\section{Auswahl einer geeigneten Untermenge an Variablen}
\label{sec:subset_of_variables}
\subsection{Vorgehen}
Um eine geeignete Untermenge an Variablen für die multivariate Analyse zu finden, haben wir die Relevanz der
Variablen, die je nach verwendetem Trainingsalgorithmus (Likelihood, Fisher, BDT, MLP) unterschiedlich ausfallen kann, evaluiert. Hierzu haben wir verschiedene Verfahren angewandt, die im Folgenden beschrieben werden.


Im Zuge der  Ausführung der Trainingsalgorithmen des vorgegebenen TMVA-Templates wird von diesem für jede Klassifizierungsmethode eine Rangliste bzgl. der Wichtigkeit der einzelnen Variablen erstellt. Um die Tauglichkeit dieser Rangliste zu überprüfen, betrachteten wir die Trainingsalgorithmen separat und trainierten den Likelihood-, Fisher-, sowie den BDT-Algorithmus jeweils insgesamt 30 mal, wobei entsprechend der vom TMVA-Template ausgegebenen Reihenfolge jeweils eine Variable entfernt wurde (beginnend mit der irrelevantesten).Bei jedem dieser insgesamt 90 Trainings wurde der ausgegebene AMS-Wert für das entsprechende Variablen-Subset protokolliert. Die Entwicklung der AMS-Werte mit abnehmender Variablenzahl sind in Abbildung \ref{fig:ams_over_parameter_count} gezeigt. Es ist deutlich zu erkennen, dass der Likelihood-Algorithmus einen ähnlichen Verlauf wie der Fisher-Algorithmus aufweist. Dies lässt sich dadurch erklären, dass es sich hierbei um ähnliche Algorithmen handelt. Eine sinnvolle Untermenge an Variablen liese sich demnach mithilfe des Maximums des AMS-Verlaufs bestimmen.

Da das Training des neuronalen Netzwerks mit Abstand die meiste Zeit benötigt, wurde hier ein anderes Verfahren angewandt: Es wurden 30 Trainingsläufe mit je einer entfernten Variablen durchgeführt und die Variablen entsprechend des jeweils erreichten AMS-Werts sortiert. Anschließend führten wir das zuvor beschriebene Verfahren gemäß dieses Rankings durch und erhielten den in Abbildung \ref{fig:ams_over_parameter_count} gezeigten Verlauf der AMS-Werte.


Dieses Verfahren stellte den Startpunkt für eine tiefergehende Analyse der Relevanz der einzelnen Variablen dar: Für jede Methode wurde das Training 30 mal mit jeweils einer aus dem Parameterset entfernten Variable durchgeführt, wobei die irrelevanteste Variable (höchster AMS-Wert) ermittelt wurde. Diese wurde aus dem Variablen-Set entfernt und das Training 29 mal durchgeführt, wobei jeweils eine der übrigen Variablen entfernt wurde. Je nach erzieltem AMS-Wert wurde das Parameter-Subset wiederum um den unwichtigsten Parameter reduziert usw. Da dieses Vorgehen aufgrund der langen Trainingszeit des neuronales Netzwerks hierfür nicht durchzuführen war, beschränkten wir uns hierbei auf die übrigen drei Verfahren. Insgesamt wurde zur Erstellung der entsprechenden Rankings das Training $3\cdot465=1395$ mal durchgeführt. Der Verlauf des AMS-Werts in Abhängigkeit der Anzahl verwendeter Parameter ist  Abbildung \ref{fig:ams_over_parameter_count} zu entnehmen. Da die AMS-Werte höher liegen als bei dem zuvor beschriebenen Verfahren, ist diese Rangliste als aussagekräftiger zu erachten.


\subsection{Auswertung}

Die Ergebnisse für den Verlauf der AMS-Werte bzgl. der verschiedenen Ranglisten sind in Abbildung \ref{fig:ams_over_parameter_count} gezeigt. Ein senkrechter Strich markiert jeweils das Maximum, anhand dessen die Auswahl der geeigneten Variablenuntermenge festgelegt wurde: Alle Variablen, die zu diesem Zeitpunkt noch Teil des Trainingsprozesses waren, sind Teil der für die weitere Auswertung der Daten gewählten Variablenuntermenge. Welche Variablen dies für die jeweiligen Trainings-Algorithmen sind, ist Tabelle \ref{table:parameter_ranking} zu entnehmen. An oberster Stelle in der Tabelle stehen dabei die für die Analyse wichtigsten Parameter. Ein waagrechter Strich zeigt die Begrenzung der Variablenuntermenge an. 

Das Verkleinerung der Variablenanzahl wirkt sich zweierlei auf die Analyse aus. Erstens kann der erreichte AMS-Wert steigen oder sinken. Zweitens reduziert sich die Trainingszeit. Anhand dieser beiden Kriterien haben wir eine Auswahl für die Untermenge an Variablen getroffen:

Eine deutliche Verbesserung des AMS-Werts durch eine Verkleinerung der Variablenanzahl zeigt sich lediglich bei der Likelihood-Methode (siehe Abbildung \ref{fig:ams_over_parameter_count}). Aus diesem Grund arbeiteten wir bei weiteren Untersuchungen dieser Methode mit der verkleinerten Variablenmenge.

Die Fisher-Methode zeigte kleine Verbesserungen des AMS-Wertes bei verkleinerter Variablenanzahl. Die Trainingslaufzeit ist allerdings so kurz, dass es kaum einen Unterschied macht, ob man den vollen Variablensatz verwendet oder einen reduzierten. Welche Auswahl im Einzelnen getroffen wurde, ist im Einzelfall dokumentiert.

Die BDT-Methode wird nur gering von der Anzahl der Variablen beeinflusst. Ob mit der vollen Variablenmenge weiter gearbeitet wurde, oder der verkleinerte Satz benutzt wurde, ist an den entsprechenden Stellen dokumentiert.

Für das neuronale Netz ist die Trainingszeit erheblich. Aus diesem Grund arbeiteten wir mit der verkleinerten Variablenuntermenge weiter.  


\begin{figure}[htp]
\begin{center}
  \includegraphics[width=\linewidth]{sections/subset_of_parameters/parameter_count_ranking_by_method.pdf}
  \caption[AMS über der Anzahl der Parameter]{AMS über der Anzahl der Variablen.}
  \label{fig:ams_over_parameter_count}
\end{center}
\end{figure}

\begin{table}
\caption{Rangliste der Variablen bzgl. ihrer Relevanz für die Analyse. Die Wichtigkeit der Parameter nimmt von oben nach unten ab. Für jede Methode ist durch einen waagrechten Strich die durch das Maximum des AMS-Verlaufs gegebene Abgrenzung einer geeigneten Auswahl an Variablen gekennzeichnet. Bei der BDT-Methode wurde unter den besten acht Parametern kein Ranking vorgenommen.}
\small
\hspace{-1cm}
\begin{tabular}{c|c|c|c}
Likelihood & Fisher & BDT & MLP \\
\hline
d\_mass\_transverse\_met\_lep & d\_mass\_transverse\_met\_lep & - & p\_jet\_num
\\
d\_mass\_vis & d\_pt\_ratio\_lep\_tau & - & d\_deltaeta\_jet\_jet \\ 
p\_tau\_pt & p\_lep\_pt & - & d\_mass\_MMC \\ 
d\_deltar\_tau\_lep & d\_mass\_vis & - & p\_jet\_leading\_pt \\ 
d\_pt\_ratio\_lep\_tau & d\_deltar\_tau\_lep & - & d\_mass\_transverse\_met\_l \\ 
p\_met & d\_pt\_h & - & p\_jet\_leading\_eta \\ 
p\_lep\_pt & p\_tau\_pt & - & d\_mass\_jet\_jet \\ 
p\_lep\_eta & d\_mass\_jet\_jet & - & p\_jet\_leading\_phi \\ 
d\_mass\_MMC & p\_met & d\_mass\_MMC & d\_pt\_h \\ 
----- & & & \\ 
p\_jet\_leading\_phi & d\_prodeta\_jet\_jet & d\_lep\_eta\_centrality & d\_mass\_vis \\ 
d\_met\_phi\_centrality & p\_jet\_subleading\_pt & p\_jet\_subleading\_phi & p\_jet\_subleading\_phi \\ 
p\_tau\_phi & p\_lep\_phi & p\_tau\_pt & d\_prodeta\_jet\_jet \\ 
p\_met\_phi & d\_mass\_MMC & d\_mass\_vis & p\_jet\_subleading\_pt \\ 
p\_tau\_eta & d\_deltaeta\_jet\_jet & p\_tau\_phi & p\_tau\_pt \\ 
 & ----- & & \\ 
p\_jet\_subleading\_pt & d\_lep\_eta\_centrality & p\_met\_sumet & p\_met\_phi \\ 
d\_pt\_tot & p\_jet\_leading\_phi & p\_lep\_pt & p\_jet\_all\_pt \\ 
p\_jet\_subleading\_eta & p\_jet\_leading\_eta & p\_lep\_phi & p\_met\_sumet \\ 
d\_prodeta\_jet\_jet & d\_sum\_pt & p\_jet\_subleading\_pt & p\_tau\_eta \\ 
 & & & ----- \\ 
p\_jet\_subleading\_phi & p\_jet\_subleading\_eta & p\_jet\_subleading\_eta & p\_met \\ 
p\_met\_sumet & p\_tau\_phi & d\_pt\_tot & d\_met\_phi\_centrality \\ 
d\_deltaeta\_jet\_jet & p\_met\_phi & p\_jet\_subleading\_eta & d\_pt\_ratio\_lep\_tau \\ 
 & & ----- & \\ 
d\_mass\_jet\_jet & p\_jet\_leading\_pt & p\_jet\_subleading\_phi & p\_tau\_phi \\ 
d\_lep\_eta\_centrality & p\_tau\_eta & p\_jet\_subleading\_pt & p\_jet\_subleading\_eta \\ 
p\_lep\_phi & p\_met\_sumet & d\_pt\_h & p\_lep\_phi \\ 
p\_jet\_num & p\_jet\_num & p\_met & d\_pt\_tot \\ 
d\_pt\_h & d\_pt\_tot & d\_prodeta\_jet\_jet & p\_lep\_eta \\ 
d\_sum\_pt & p\_lep\_eta & p\_lep\_pt & d\_sum\_pt \\ 
p\_jet\_leading\_pt & p\_jet\_subleading\_phi & d\_pt\_tot & d\_lep\_eta\_centrality \\ 
p\_jet\_all\_pt & p\_jet\_all\_pt & p\_met\_phi & p\_lep\_pt \\ 
p\_jet\_leading\_eta & d\_met\_phi\_centrality & p\_lep\_phi & d\_deltar\_tau\_lep

\end{tabular}
\label{table:parameter_ranking}
\end{table}