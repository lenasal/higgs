\section{Optimierung der Parameter des Neuronalen Netzes}
Als (künstliches) Neuronales Netz wird im Allgemeinen jede Annsammlung von verbundenen Neuronen bezeichnet, die ein individuelles Ansprechverhalten zu einem gegebenen Input Signal aufweisen. Das Neuronale Netz besteht meist aus mehreren Schichten, wobei die erste von Input Neuronen und die letzte die Output Neuronen darstellen. In unserem Fall besteht das Output-layer aus lediglich einem Neuron, da nur zwishcen Signal und Background unterschieden werden muss.\\ \\
Um die Zeit zu verringern, die das NN benötigt um die Daten zu trainieren, wurde mit der Option Sampling=0.X gearbeitet welche nur den X-ten Anteil der Trainings- und Testdatensätze verwendet. Zwar muss man dadurch einen etwas schlechteren AMS-Wert in Kauf nehmen, die Laufzeit verringert sich jedoch enorm. Das Sampling wurde benutzt um den Parameter NCycles und die Anzahgl der Hiddenlayers zu optimieren. Eine Variation dieser Paramter hatte allerdings eine recht marginale Auswirkung auf den AMS, wie sich im Folgenden zeigen wird. Außerdem konnte aufgrund der langen Laufzeit nicht wahllos beliebig viele Parameterkonfigurationen ausprobiert werden.\\ \\
Zunächst wurde bei den festen Parametern NCycles = 100,400,700,1000 der Parameter HiddenLayer =N+5,N zu HiddenLayer =N+5,N variiert (siehe Abb xyz). Es stellte sich heraus, dass die N+5,N layer Architektur minimal besser abschnitt. \\ \\
Um das Verhalten bei großen Anzahlen von Zyklendurchläufen zu untersuchen wurde zusätzlich bei Sampling=0.6 die Cycles=650,750,800,5000,10000 ausgewertet (siehe Abb xzy). Eine signifikante Erhöhung der Cycle Anzahl hatte zwar eine rießige Laufzeitverlängerung zur Auswirkung, aber keine Verbesserung des AMS; im Gegenteil dieser hatte sich sogar minimal verschlechtert. \\ \\
Im Folgenden wurde der Bereich um Cycles = 700 näher untersucht, da vermutetr wird dass dort der AMS am besten ist. Hierzu wurden die Cycles =800, 780, 760, 740, 720, 700, 680 mit einem Sampling=0.6 simuliert (Abb. blabla). Da diese Abbildung noch keinen Schlussfolgerungen zulässt wurde in dem darauffolgenden Schritt die Stepsize der cycles verringert und erneut ausgewertet (dieses Mal unter Verwendung des vollen Trainings- und Testdatensatzes, Sampling =False) (siehe Abb sssds). Es stellte sich heraus, dass der AMS bei NCycles $\approx$640 den größten Wert von 0.6215 annimmt. Da dieser Wert jedoch bei Weitem nicht mit dem des BDT mithalten kann, wurde das NN als Methode verworfen. \\ \\